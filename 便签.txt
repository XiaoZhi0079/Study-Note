1.vue3笔记 
2.TS+JS笔记
3.boss直聘

6.linux基本命令


9.SearXNG 联网搜索数据优化
10.SSE管道


11. CICD流水线

14.切片优化策略


15.挖掘spring ai记忆 

16.文档识别 清晰 策略   OCR模型  qwen-vl-ocr-2025-11-20

  
v-bind  v-on v-model



defaultsystem应该全局唯一   在yml文件中写定 且不能更改

prompt可以指定


ai数据库

spirngai多模态仅支持上传图片    
springai工具类要注册成bean 否则打包为原生镜像会失效  原生镜像：无需jre jdk机器可直接执行的文件
springai工具类的返回值必须是可序列化的 因为结果要序列化返回大模型





2. RAG（检索增强生成）核心模块实施方案

知识库构建阶段（离线处理）：
1.	文档加载与清洗：管理员上传学生手册、规章制度等文件，系统利用 spring-ai-tika-document-reader 解析文本，去除乱码和无关字符，如若处理效果不当，则参考专业的OCR大模型的解析成果。
2.	文档切片（Chunking）：根据语义完整性或固定的切割的逻辑（比如多空行切割），将长文档切分为较短文本片段。另外还要考虑保留重叠部分以维持语义连贯性。
3.	向量化嵌入：调用 Embedding 模型将文本片段转化为向量，存入向量数据库redis-stack。
问答检索阶段（在线处理）：
1.	提问：考虑对用户的提问进行改写，较模糊则引导用户提问。
2.	混合检索：如果问题涉及结构化数据（如“我的高数成绩”），系统直接通过 MyBatis 查询 MySQL 数据库；如果问题涉及非结构化知识（如“请假流程”），则计算问题向量与知识库向量的余弦相似度（Cosine Similarity），召回 Top-K 相关片段 。
3.	上下文拼接与生成：将召回的知识片段作为“上下文（Context）”，结合预设的系统提示词（System Prompt），组装成完整的 Prompt 发送给大模型，生成基于事实的回答。


开启simpleadviors 查看日志 是否能召回相似的文档






[root@iZ7xvdtdi3p11x69rfhfx6Z frp]# cat frpc.toml 
serverAddr = "127.0.0.1"
serverPort = 7000

[[proxies]]
name = "test-tcp"
type = "tcp"
localIP = "127.0.0.1"
localPort = 22
remotePort = 6000
[root@iZ7xvdtdi3p11x69rfhfx6Z frp]# cat frps.toml 
[common]
bindPort = 7000
token = "1968zhss"


{
    "registry-mirrors": [
        "https://docker.1ms.run",
        "https://s18srhdi.mirror.aliyuncs.com",
        "https://registry.docker-cn.com"
    ],
    "dns": [
        "1.1.1.1",
        "8.8.8.8"
    ]
}

